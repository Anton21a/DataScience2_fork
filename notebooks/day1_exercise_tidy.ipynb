{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 Exercise: Cleaning Messy Cafe Sales Data\n",
    "\n",
    "**Name:** _[Your name here]_  \n",
    "**Date:** October 8, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Transform a messy cafe sales dataset into a tidy format, designate and validate a primary key, and create summary tables.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "**File:** `../data/day1/dirty_cafe_sales.csv`  \n",
    "**Rows:** 10,000 cafe transactions  \n",
    "**Data Dictionary:** See `../data/day1/README.md`\n",
    "\n",
    "## Deliverable\n",
    "\n",
    "This notebook should **\"Restart & Run All\"** successfully when you're done!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Data Loading\n",
    "\n",
    "### TODO 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.209933Z",
     "iopub.status.busy": "2025-10-07T15:04:46.209694Z",
     "iopub.status.idle": "2025-10-07T15:04:46.438072Z",
     "shell.execute_reply": "2025-10-07T15:04:46.417622Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 1: Import pandas and numpy\n",
    "# Uncomment the lines below and run this cell:\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.440722Z",
     "iopub.status.busy": "2025-10-07T15:04:46.440379Z",
     "iopub.status.idle": "2025-10-07T15:04:46.462010Z",
     "shell.execute_reply": "2025-10-07T15:04:46.461575Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 2: Load the data\n",
    "# Uncomment the lines below and run this cell:\n",
    "\n",
    "# df = pd.read_csv('../data/day1/dirty_cafe_sales.csv')\n",
    "# print(f\"✅ Data loaded: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Initial Exploration\n",
    "\n",
    "Before cleaning, let's understand what we have.\n",
    "\n",
    "### TODO 3: Display basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.464191Z",
     "iopub.status.busy": "2025-10-07T15:04:46.464024Z",
     "iopub.status.idle": "2025-10-07T15:04:46.482623Z",
     "shell.execute_reply": "2025-10-07T15:04:46.479854Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 3: Display the shape of the dataframe\n",
    "# Uncomment and run:\n",
    "\n",
    "# print(f\"Dataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.485196Z",
     "iopub.status.busy": "2025-10-07T15:04:46.485040Z",
     "iopub.status.idle": "2025-10-07T15:04:46.495469Z",
     "shell.execute_reply": "2025-10-07T15:04:46.495254Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 3 (continued): Display the first 10 rows\n",
    "# Uncomment and run:\n",
    "\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.496515Z",
     "iopub.status.busy": "2025-10-07T15:04:46.496446Z",
     "iopub.status.idle": "2025-10-07T15:04:46.498170Z",
     "shell.execute_reply": "2025-10-07T15:04:46.497985Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 3 (continued): Display column names and types\n",
    "# Uncomment and run:\n",
    "\n",
    "# print(\"Column Types:\")\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 4: Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.499132Z",
     "iopub.status.busy": "2025-10-07T15:04:46.499075Z",
     "iopub.status.idle": "2025-10-07T15:04:46.501936Z",
     "shell.execute_reply": "2025-10-07T15:04:46.501755Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 4: Count missing values (NaN) in each column\n",
    "# Uncomment and run:\n",
    "\n",
    "# print(\"Missing Values (NaN) per column:\")\n",
    "# print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 5: Check for sentinel values\n",
    "\n",
    "Look for \"ERROR\" and \"UNKNOWN\" in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.502807Z",
     "iopub.status.busy": "2025-10-07T15:04:46.502751Z",
     "iopub.status.idle": "2025-10-07T15:04:46.506074Z",
     "shell.execute_reply": "2025-10-07T15:04:46.505900Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 5: Count \"ERROR\" values in each column\n",
    "# Uncomment and run:\n",
    "\n",
    "# print(\"'ERROR' values per column:\")\n",
    "# print((df == 'ERROR').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.506929Z",
     "iopub.status.busy": "2025-10-07T15:04:46.506876Z",
     "iopub.status.idle": "2025-10-07T15:04:46.510229Z",
     "shell.execute_reply": "2025-10-07T15:04:46.510069Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 5 (continued): Count \"UNKNOWN\" values in each column\n",
    "# Uncomment and run:\n",
    "\n",
    "# print(\"'UNKNOWN' values per column:\")\n",
    "# print((df == 'UNKNOWN').sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: What Issues Did You Find?\n",
    "\n",
    "**TODO:** Write 2-3 sentences describing the data quality issues you observed.\n",
    "\n",
    "_[Your reflection here]_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Is This Data Tidy?\n",
    "\n",
    "### TODO 6: Evaluate against tidy data principles\n",
    "\n",
    "**The Three Rules:**\n",
    "1. Each variable is a column\n",
    "2. Each observation is a row\n",
    "3. Each value is a cell\n",
    "\n",
    "**Questions to answer in markdown:**\n",
    "\n",
    "1. What is the unit of observation in this dataset? (What does each row represent?)\n",
    "\n",
    "_[Your answer]_\n",
    "\n",
    "2. Does each variable have its own column?\n",
    "\n",
    "_[Your answer]_\n",
    "\n",
    "3. Is this dataset tidy? Why or why not?\n",
    "\n",
    "_[Your answer]_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Identify and Validate Primary Key\n",
    "\n",
    "### TODO 7: Identify the primary key candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.511281Z",
     "iopub.status.busy": "2025-10-07T15:04:46.511233Z",
     "iopub.status.idle": "2025-10-07T15:04:46.513780Z",
     "shell.execute_reply": "2025-10-07T15:04:46.513619Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 7: Check if 'Transaction ID' is unique\n",
    "# Uncomment and run:\n",
    "\n",
    "# is_unique = df['Transaction ID'].is_unique\n",
    "# print(f\"Is 'Transaction ID' unique? {is_unique}\")\n",
    "# print(f\"Total rows: {len(df):,}\")\n",
    "# print(f\"Unique Transaction IDs: {df['Transaction ID'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.514598Z",
     "iopub.status.busy": "2025-10-07T15:04:46.514547Z",
     "iopub.status.idle": "2025-10-07T15:04:46.516004Z",
     "shell.execute_reply": "2025-10-07T15:04:46.515830Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 7 (continued): Check for any NULL values in 'Transaction ID'\n",
    "# Uncomment and run:\n",
    "\n",
    "# null_count = df['Transaction ID'].isnull().sum()\n",
    "# print(f\"NULL Transaction IDs: {null_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.516804Z",
     "iopub.status.busy": "2025-10-07T15:04:46.516757Z",
     "iopub.status.idle": "2025-10-07T15:04:46.518668Z",
     "shell.execute_reply": "2025-10-07T15:04:46.518473Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 7 (continued): If there are duplicates, find them\n",
    "# Uncomment and run:\n",
    "\n",
    "# duplicates = df[df.duplicated(subset=['Transaction ID'], keep=False)]\n",
    "# print(f\"Duplicate rows: {len(duplicates)}\")\n",
    "# if len(duplicates) > 0:\n",
    "#     print(\"\\nShowing first few duplicates:\")\n",
    "#     display(duplicates.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 8: Write validation assertions\n",
    "\n",
    "Once you've confirmed (or fixed) the primary key, write assertions to prove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.519590Z",
     "iopub.status.busy": "2025-10-07T15:04:46.519522Z",
     "iopub.status.idle": "2025-10-07T15:04:46.521654Z",
     "shell.execute_reply": "2025-10-07T15:04:46.521471Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 8: Add assertions to validate primary key\n",
    "# Uncomment and run (these will error if checks fail):\n",
    "\n",
    "# assert df['Transaction ID'].is_unique, \"❌ Duplicate transaction IDs found\"\n",
    "# assert df['Transaction ID'].notna().all(), \"❌ NULL transaction IDs found\"\n",
    "# print(\"✅ Transaction ID is a valid primary key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: Primary Key\n",
    "\n",
    "**TODO:** Explain what you found and any decisions you made.\n",
    "\n",
    "_[Your reflection here: Is Transaction ID a good primary key? Did you find any issues? How did you handle them?]_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Handle Missing Values\n",
    "\n",
    "### TODO 9: Standardize missing value representations\n",
    "\n",
    "Convert \"ERROR\", \"UNKNOWN\", and empty strings to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.522538Z",
     "iopub.status.busy": "2025-10-07T15:04:46.522486Z",
     "iopub.status.idle": "2025-10-07T15:04:46.527943Z",
     "shell.execute_reply": "2025-10-07T15:04:46.527763Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 9: Replace sentinel values with NaN\n",
    "# Uncomment and run:\n",
    "\n",
    "# df = df.replace(['ERROR', 'UNKNOWN', ''], np.nan)\n",
    "# print(\"✅ Replaced 'ERROR', 'UNKNOWN', and empty strings with NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.528822Z",
     "iopub.status.busy": "2025-10-07T15:04:46.528775Z",
     "iopub.status.idle": "2025-10-07T15:04:46.532581Z",
     "shell.execute_reply": "2025-10-07T15:04:46.532392Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 9 (continued): Check missing values again after standardization\n",
    "# Uncomment and run:\n",
    "\n",
    "# print(\"Missing values after standardization:\")\n",
    "# print(df.isnull().sum())\n",
    "# print(f\"\\nTotal missing values: {df.isnull().sum().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 10: Decide how to handle missing values\n",
    "\n",
    "**Options:**\n",
    "- Drop rows with missing values in critical columns\n",
    "- Fill with default values\n",
    "- Keep as NaN (document impact on analysis)\n",
    "\n",
    "**Your strategy:**\n",
    "\n",
    "_[Write your strategy here. Example: \"I will keep NaN for Payment Method because it represents missing data at point of sale. These transactions will be excluded from payment method analysis but included in overall sales totals.\"]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.533490Z",
     "iopub.status.busy": "2025-10-07T15:04:46.533442Z",
     "iopub.status.idle": "2025-10-07T15:04:46.534783Z",
     "shell.execute_reply": "2025-10-07T15:04:46.534569Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 10: Implement your missing value strategy\n",
    "# This is a decision point - choose your approach!\n",
    "# Below is ONE option: Keep NaN as-is (document in reflection above)\n",
    "# Uncomment and run:\n",
    "\n",
    "# For this exercise, we'll keep NaN values and handle them in analysis\n",
    "# (You could also drop rows or fill values - document your choice above!)\n",
    "# print(\"✅ Missing value strategy: Keeping NaN, will exclude from specific analyses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Fix Type Issues\n",
    "\n",
    "### TODO 11: Convert Quantity to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.535598Z",
     "iopub.status.busy": "2025-10-07T15:04:46.535553Z",
     "iopub.status.idle": "2025-10-07T15:04:46.539063Z",
     "shell.execute_reply": "2025-10-07T15:04:46.538864Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 11: Convert Quantity to integer\n",
    "# Uncomment and run:\n",
    "\n",
    "# df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce').astype('Int64')\n",
    "# print(\"✅ Quantity converted to Int64 (allows NaN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 12: Convert prices to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.540025Z",
     "iopub.status.busy": "2025-10-07T15:04:46.539977Z",
     "iopub.status.idle": "2025-10-07T15:04:46.542702Z",
     "shell.execute_reply": "2025-10-07T15:04:46.542447Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 12: Convert 'Price Per Unit' to float\n",
    "# Uncomment and run:\n",
    "\n",
    "# df['Price Per Unit'] = pd.to_numeric(df['Price Per Unit'], errors='coerce')\n",
    "# print(\"✅ 'Price Per Unit' converted to float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.543788Z",
     "iopub.status.busy": "2025-10-07T15:04:46.543719Z",
     "iopub.status.idle": "2025-10-07T15:04:46.546208Z",
     "shell.execute_reply": "2025-10-07T15:04:46.546006Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 12 (continued): Convert 'Total Spent' to float\n",
    "# Uncomment and run:\n",
    "\n",
    "# df['Total Spent'] = pd.to_numeric(df['Total Spent'], errors='coerce')\n",
    "# print(\"✅ 'Total Spent' converted to float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 13: Convert Transaction Date to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.547128Z",
     "iopub.status.busy": "2025-10-07T15:04:46.547078Z",
     "iopub.status.idle": "2025-10-07T15:04:46.549875Z",
     "shell.execute_reply": "2025-10-07T15:04:46.549692Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 13: Parse Transaction Date as datetime\n",
    "# Uncomment and run:\n",
    "\n",
    "# df['Transaction Date'] = pd.to_datetime(df['Transaction Date'], errors='coerce')\n",
    "# print(\"✅ 'Transaction Date' converted to datetime64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 14: Verify types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.550815Z",
     "iopub.status.busy": "2025-10-07T15:04:46.550766Z",
     "iopub.status.idle": "2025-10-07T15:04:46.552242Z",
     "shell.execute_reply": "2025-10-07T15:04:46.552045Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 14: Display dtypes to verify conversions worked\n",
    "# Uncomment and run:\n",
    "\n",
    "# print(\"Updated Column Types:\")\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 15: Write type assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.553142Z",
     "iopub.status.busy": "2025-10-07T15:04:46.553090Z",
     "iopub.status.idle": "2025-10-07T15:04:46.554653Z",
     "shell.execute_reply": "2025-10-07T15:04:46.554489Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 15: Add assertions to validate types\n",
    "# Uncomment and run:\n",
    "\n",
    "# assert df['Quantity'].dtype in ['int64', 'Int64'], \"❌ Quantity should be integer\"\n",
    "# assert df['Price Per Unit'].dtype == 'float64', \"❌ Price should be float\"\n",
    "# assert df['Transaction Date'].dtype == 'datetime64[ns]', \"❌ Date should be datetime\"\n",
    "# print(\"✅ All types are correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7: Validate Data Integrity\n",
    "\n",
    "### TODO 16: Check if Total Spent = Quantity × Price Per Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.555503Z",
     "iopub.status.busy": "2025-10-07T15:04:46.555442Z",
     "iopub.status.idle": "2025-10-07T15:04:46.557108Z",
     "shell.execute_reply": "2025-10-07T15:04:46.556928Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 16: Calculate expected total\n",
    "# Uncomment and run:\n",
    "\n",
    "# df['Calculated Total'] = df['Quantity'] * df['Price Per Unit']\n",
    "# print(\"✅ Calculated expected totals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.558130Z",
     "iopub.status.busy": "2025-10-07T15:04:46.558073Z",
     "iopub.status.idle": "2025-10-07T15:04:46.560329Z",
     "shell.execute_reply": "2025-10-07T15:04:46.560128Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 16 (continued): Compare with actual Total Spent\n",
    "# This uses np.isclose() for float comparison (allows tiny rounding differences)\n",
    "# Uncomment and run:\n",
    "\n",
    "# mask = df['Total Spent'].notna() & df['Calculated Total'].notna()\n",
    "# mismatches = ~np.isclose(\n",
    "#     df.loc[mask, 'Total Spent'], \n",
    "#     df.loc[mask, 'Calculated Total'],\n",
    "#     rtol=1e-05  # Relative tolerance for floating point comparison\n",
    "# )\n",
    "# print(f\"Mismatches found: {mismatches.sum()} out of {mask.sum()} rows with data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 17: Check for impossible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.561232Z",
     "iopub.status.busy": "2025-10-07T15:04:46.561176Z",
     "iopub.status.idle": "2025-10-07T15:04:46.562716Z",
     "shell.execute_reply": "2025-10-07T15:04:46.562539Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 17: Check for negative or zero prices\n",
    "# Uncomment and run:\n",
    "\n",
    "# bad_prices = df[df['Price Per Unit'] <= 0]\n",
    "# print(f\"Rows with price <= 0: {len(bad_prices)}\")\n",
    "# if len(bad_prices) > 0:\n",
    "#     display(bad_prices[['Transaction ID', 'Item', 'Price Per Unit']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.563497Z",
     "iopub.status.busy": "2025-10-07T15:04:46.563445Z",
     "iopub.status.idle": "2025-10-07T15:04:46.565297Z",
     "shell.execute_reply": "2025-10-07T15:04:46.565115Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 17 (continued): Check for zero or negative quantities\n",
    "# Uncomment and run:\n",
    "\n",
    "# bad_qty = df[df['Quantity'] <= 0]\n",
    "# print(f\"Rows with quantity <= 0: {len(bad_qty)}\")\n",
    "# if len(bad_qty) > 0:\n",
    "#     display(bad_qty[['Transaction ID', 'Item', 'Quantity']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection: Data Integrity\n",
    "\n",
    "**TODO:** What did you find? How did you handle integrity issues?\n",
    "\n",
    "_[Your reflection here]_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 8: Create Summary Tables\n",
    "\n",
    "Now that data is clean, answer some business questions!\n",
    "\n",
    "### TODO 18: Total sales by payment method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.566235Z",
     "iopub.status.busy": "2025-10-07T15:04:46.566168Z",
     "iopub.status.idle": "2025-10-07T15:04:46.570008Z",
     "shell.execute_reply": "2025-10-07T15:04:46.569806Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 18: Calculate total revenue and transaction count by payment method\n",
    "# Uncomment and run (this one is fully worked as an example):\n",
    "\n",
    "# payment_summary = df.groupby('Payment Method').agg({\n",
    "#     'Total Spent': 'sum',\n",
    "#     'Transaction ID': 'count'\n",
    "# }).round(2)\n",
    "# \n",
    "# payment_summary.columns = ['Total Revenue', 'Transaction Count']\n",
    "# payment_summary = payment_summary.sort_values('Total Revenue', ascending=False)\n",
    "# \n",
    "# print(\"Sales by Payment Method:\")\n",
    "# display(payment_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 19: Most popular items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.570993Z",
     "iopub.status.busy": "2025-10-07T15:04:46.570938Z",
     "iopub.status.idle": "2025-10-07T15:04:46.573583Z",
     "shell.execute_reply": "2025-10-07T15:04:46.573374Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 19: Find most popular items by quantity sold\n",
    "# Pattern: df.groupby('Column')['Metric'].sum().sort_values(ascending=False)\n",
    "# Uncomment and adapt:\n",
    "\n",
    "# popular_items = df.groupby('Item')['Quantity'].sum().sort_values(ascending=False)\n",
    "# print(\"Most Popular Items (by quantity):\")\n",
    "# display(popular_items.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.574483Z",
     "iopub.status.busy": "2025-10-07T15:04:46.574434Z",
     "iopub.status.idle": "2025-10-07T15:04:46.576985Z",
     "shell.execute_reply": "2025-10-07T15:04:46.576782Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 19 (continued): Find highest revenue items\n",
    "# Use the same pattern but with 'Total Spent' instead of 'Quantity'\n",
    "# Uncomment and adapt:\n",
    "\n",
    "# revenue_items = df.groupby('Item')['Total Spent'].sum().sort_values(ascending=False).round(2)\n",
    "# print(\"Highest Revenue Items:\")\n",
    "# display(revenue_items.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 20: Location comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.577896Z",
     "iopub.status.busy": "2025-10-07T15:04:46.577846Z",
     "iopub.status.idle": "2025-10-07T15:04:46.581760Z",
     "shell.execute_reply": "2025-10-07T15:04:46.581591Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 20: Compare transaction volume and average transaction value by location\n",
    "# This uses .agg() with multiple functions (like TODO 18)\n",
    "# Uncomment and run:\n",
    "\n",
    "# location_summary = df.groupby('Location').agg({\n",
    "#     'Transaction ID': 'count',\n",
    "#     'Total Spent': ['sum', 'mean']\n",
    "# }).round(2)\n",
    "# \n",
    "# location_summary.columns = ['Transaction Count', 'Total Revenue', 'Avg Transaction Value']\n",
    "# print(\"Sales by Location:\")\n",
    "# display(location_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9: Final Validation\n",
    "\n",
    "### TODO 21: Run all validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-07T15:04:46.582652Z",
     "iopub.status.busy": "2025-10-07T15:04:46.582603Z",
     "iopub.status.idle": "2025-10-07T15:04:46.585210Z",
     "shell.execute_reply": "2025-10-07T15:04:46.585031Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO 21: Gather all your assertions in one cell to prove data quality\n",
    "# Uncomment and run:\n",
    "\n",
    "# print(\"Running final validation...\\n\")\n",
    "# \n",
    "# # Primary key\n",
    "# assert df['Transaction ID'].is_unique, \"❌ Duplicate transaction IDs\"\n",
    "# assert df['Transaction ID'].notna().all(), \"❌ NULL transaction IDs\"\n",
    "# print(\"✅ Primary key validated\")\n",
    "# \n",
    "# # Types\n",
    "# assert df['Quantity'].dtype in ['int64', 'Int64'], \"❌ Quantity type wrong\"\n",
    "# assert df['Price Per Unit'].dtype == 'float64', \"❌ Price type wrong\"\n",
    "# assert df['Transaction Date'].dtype == 'datetime64[ns]', \"❌ Date type wrong\"\n",
    "# print(\"✅ Types validated\")\n",
    "# \n",
    "# # Data ranges (only check non-null values)\n",
    "# assert (df['Quantity'].dropna() > 0).all(), \"❌ Invalid quantities found\"\n",
    "# assert (df['Price Per Unit'].dropna() > 0).all(), \"❌ Invalid prices found\"\n",
    "# print(\"✅ Data ranges validated\")\n",
    "# \n",
    "# print(\"\\n✅ All validations passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 10: Documentation\n",
    "\n",
    "### TODO 22: Document your data cleaning process\n",
    "\n",
    "Write a brief summary (8-10 sentences) of:\n",
    "1. What problems you found\n",
    "2. What decisions you made\n",
    "3. What the implications are for analysis\n",
    "4. What a stakeholder should know about this data\n",
    "\n",
    "---\n",
    "\n",
    "## Data Cleaning Summary\n",
    "\n",
    "_[Your summary here]_\n",
    "\n",
    "### Issues Found\n",
    "- _[List major issues]_\n",
    "\n",
    "### Actions Taken\n",
    "- _[List your cleaning steps]_\n",
    "\n",
    "### Assumptions Made\n",
    "- _[List key assumptions]_\n",
    "\n",
    "### Implications for Analysis\n",
    "- _[What should analysts know?]_\n",
    "\n",
    "### Data Quality Assessment\n",
    "- _[Overall, how clean is this data now? What percentage is usable?]_\n",
    "\n",
    "---\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've successfully cleaned a real messy dataset using tidy data principles!\n",
    "\n",
    "**Final check:** Can you **\"Restart & Run All\"** successfully? That's the gold standard!\n",
    "\n",
    "**Reflection:** What was the hardest part? What did you learn?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
