{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b73a1e",
   "metadata": {},
   "source": [
    "# Day 2, Block B: JSON → DuckDB Pipeline\n",
    "\n",
    "**Duration:** 40-45 minutes  \n",
    "**Course:** ECBS5294 - Introduction to Data Science: Working with Data  \n",
    "**Instructor:** Eduardo Ariño de la Rubia\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "\n",
    "1. **Explain** why nested JSON needs normalization (tidy data principles)\n",
    "2. **Normalize** nested JSON structures into multiple related tables\n",
    "3. **Use pandas** to flatten one-to-many relationships\n",
    "4. **Persist** normalized data to DuckDB for SQL analysis\n",
    "5. **Join** normalized tables to answer business questions\n",
    "6. **Validate** data quality with assertions\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b26d64",
   "metadata": {},
   "source": [
    "## Part 1: The Normalization Problem (⏱️ 8-10 minutes)\n",
    "\n",
    "### Recall: Tidy Data Principles (Day 1)\n",
    "\n",
    "On Day 1, we learned **tidy data principles:**\n",
    "\n",
    "1. Each **variable** is a column\n",
    "2. Each **observation** is a row\n",
    "3. Each **type of observational unit** forms a table\n",
    "\n",
    "**The problem:** Nested JSON violates these principles!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f516621",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.089471Z",
     "iopub.status.busy": "2025-10-12T16:28:32.089248Z",
     "iopub.status.idle": "2025-10-12T16:28:32.355731Z",
     "shell.execute_reply": "2025-10-12T16:28:32.355201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup: Import libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d05a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.357745Z",
     "iopub.status.busy": "2025-10-12T16:28:32.357623Z",
     "iopub.status.idle": "2025-10-12T16:28:32.748967Z",
     "shell.execute_reply": "2025-10-12T16:28:32.748522Z"
    }
   },
   "outputs": [],
   "source": [
    "# OPTION 1: Use live API (DEFAULT)\n",
    "DUMMYJSON_URL = \"https://dummyjson.com/products\"\n",
    "\n",
    "response = requests.get(DUMMYJSON_URL, params={'limit': 30}, timeout=10)\n",
    "response.raise_for_status()\n",
    "products_data = response.json()\n",
    "\n",
    "print(f\"✅ Fetched {len(products_data['products'])} products from API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35993db4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.750421Z",
     "iopub.status.busy": "2025-10-12T16:28:32.750318Z",
     "iopub.status.idle": "2025-10-12T16:28:32.751976Z",
     "shell.execute_reply": "2025-10-12T16:28:32.751664Z"
    }
   },
   "outputs": [],
   "source": [
    "# OPTION 2: Use backup file (if API is down)\n",
    "# Uncomment these lines and skip the cell above if DummyJSON is unavailable\n",
    "\n",
    "# import json\n",
    "# with open('../../data/day2/block_b/products_backup.json') as f:\n",
    "#     products_data = json.load(f)\n",
    "# \n",
    "# print(f\"✅ Loaded {len(products_data['products'])} products from backup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28a187",
   "metadata": {},
   "source": [
    "### The Problem: One-to-Many Relationships\n",
    "\n",
    "Look at a single product with its nested reviews:\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9cafe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.753326Z",
     "iopub.status.busy": "2025-10-12T16:28:32.753232Z",
     "iopub.status.idle": "2025-10-12T16:28:32.755787Z",
     "shell.execute_reply": "2025-10-12T16:28:32.755542Z"
    }
   },
   "outputs": [],
   "source": [
    "# Examine one product with nested reviews\n",
    "sample_product = products_data['products'][0]\n",
    "\n",
    "print(\"Product structure:\")\n",
    "print(f\"  ID: {sample_product['id']}\")\n",
    "print(f\"  Title: {sample_product['title']}\")\n",
    "print(f\"  Price: ${sample_product['price']}\")\n",
    "print(f\"\\n  Reviews ({len(sample_product['reviews'])} reviews):\")\n",
    "\n",
    "for i, review in enumerate(sample_product['reviews'], 1):\n",
    "    print(f\"    Review {i}: {review['rating']}⭐ - {review['reviewerName']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Problem: One product has MANY reviews.\")\n",
    "print(\"This is a ONE-TO-MANY relationship - not tidy!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea50af7",
   "metadata": {},
   "source": [
    "### Why This Matters for Business\n",
    "\n",
    "**Questions we want to answer:**\n",
    "- What's the average rating across all reviews? (need to count reviews, not products!)\n",
    "- Which reviewers are most active? (need to count by reviewer)\n",
    "- How many reviews per product? (need to aggregate reviews by product)\n",
    "\n",
    "**We can't answer these questions cleanly with nested JSON.**\n",
    "\n",
    "**Solution:** Create two separate tables:\n",
    "1. **Products table** - One row per product (product-level attributes only)\n",
    "2. **Reviews table** - One row per review (with `product_id` foreign key)\n",
    "\n",
    "This is called **normalization** - the process of organizing data to reduce redundancy and improve integrity.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334784ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Normalize with Pandas (⏱️ 12-15 minutes)\n",
    "\n",
    "### Strategy: Create Multiple Tidy Tables\n",
    "\n",
    "We'll create two tables:\n",
    "1. **`products`** - Product-level attributes (id, title, price, category, brand, stock)\n",
    "2. **`reviews`** - Review-level attributes (product_id, rating, comment, reviewer)\n",
    "\n",
    "The `product_id` in the reviews table is a **foreign key** that links back to the products table.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a789bc1",
   "metadata": {},
   "source": [
    "### Step 1: Extract Products Table\n",
    "\n",
    "First, let's create a DataFrame with only product-level attributes:\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3bac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.757087Z",
     "iopub.status.busy": "2025-10-12T16:28:32.757001Z",
     "iopub.status.idle": "2025-10-12T16:28:32.763646Z",
     "shell.execute_reply": "2025-10-12T16:28:32.763437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract products (top-level attributes only)\n",
    "products_list = []\n",
    "\n",
    "for product in products_data['products']:\n",
    "    products_list.append({\n",
    "        'product_id': product['id'],\n",
    "        'title': product['title'],\n",
    "        'price': product['price'],\n",
    "        'category': product['category'],\n",
    "        'brand': product.get('brand', 'Unknown'),  # Safe access\n",
    "        'stock': product.get('stock', 0),\n",
    "        'rating': product.get('rating', None)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "products_df = pd.DataFrame(products_list)\n",
    "\n",
    "print(f\"✅ Created products table: {products_df.shape[0]} rows × {products_df.shape[1]} columns\")\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kyrfkadh02g",
   "metadata": {},
   "source": [
    "### Validation Pattern: Assert Data Quality\n",
    "\n",
    "> **\"Never assume data is clean. Prove it with assertions.\"**\n",
    "\n",
    "**Why validate?**\n",
    "- Catch data quality issues early (before they corrupt downstream analysis)\n",
    "- Document assumptions (primary keys ARE unique)\n",
    "- Fail fast with clear error messages (debugging is easier)\n",
    "\n",
    "**Production pattern:**\n",
    "```python\n",
    "assert df['id_column'].is_unique, \"Duplicate IDs found!\"\n",
    "assert df['required_column'].notna().all(), \"NULL values in required field!\"\n",
    "```\n",
    "\n",
    "Let's validate our products table:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diqkbw8ptuj",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.764809Z",
     "iopub.status.busy": "2025-10-12T16:28:32.764742Z",
     "iopub.status.idle": "2025-10-12T16:28:32.767503Z",
     "shell.execute_reply": "2025-10-12T16:28:32.767281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validate products table\n",
    "print(\"✅ Validating products table...\")\n",
    "\n",
    "# Check 1: Primary key uniqueness\n",
    "assert products_df['product_id'].is_unique, \\\n",
    "    f\"❌ Duplicate product IDs found! Expected {len(products_df)} unique IDs, found {products_df['product_id'].nunique()}\"\n",
    "\n",
    "print(f\"   ✓ All {len(products_df)} product IDs are unique (PK check passed)\")\n",
    "\n",
    "# Check 2: No NULL primary keys\n",
    "assert products_df['product_id'].notna().all(), \\\n",
    "    f\"❌ NULL product IDs found! {products_df['product_id'].isna().sum()} rows have NULL IDs\"\n",
    "\n",
    "print(f\"   ✓ No NULL product IDs (PK integrity check passed)\")\n",
    "\n",
    "# Check 3: Required fields are populated\n",
    "required_fields = ['title', 'price', 'category']\n",
    "for field in required_fields:\n",
    "    null_count = products_df[field].isna().sum()\n",
    "    assert null_count == 0, \\\n",
    "        f\"❌ Found {null_count} NULL values in required field '{field}'\"\n",
    "\n",
    "print(f\"   ✓ All required fields populated ({', '.join(required_fields)})\")\n",
    "\n",
    "print(\"\\n✅ Products table validation: PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e9e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.768548Z",
     "iopub.status.busy": "2025-10-12T16:28:32.768484Z",
     "iopub.status.idle": "2025-10-12T16:28:32.770643Z",
     "shell.execute_reply": "2025-10-12T16:28:32.770438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify products table structure\n",
    "print(\"Products table info:\")\n",
    "print(f\"  Shape: {products_df.shape}\")\n",
    "print(f\"  Columns: {list(products_df.columns)}\")\n",
    "print(f\"  Data types:\\n{products_df.dtypes}\")\n",
    "print(f\"\\n  Unique products: {products_df['product_id'].nunique()}\")\n",
    "print(f\"  Categories: {products_df['category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317b811",
   "metadata": {},
   "source": [
    "### Step 2: Extract Reviews Table (Explode One-to-Many)\n",
    "\n",
    "Now for the tricky part: **exploding the reviews array** into separate rows.\n",
    "\n",
    "Each review becomes its own row, with a `product_id` foreign key linking back to the product.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51cb7bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.771708Z",
     "iopub.status.busy": "2025-10-12T16:28:32.771648Z",
     "iopub.status.idle": "2025-10-12T16:28:32.775352Z",
     "shell.execute_reply": "2025-10-12T16:28:32.775159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract reviews (explode one-to-many)\n",
    "reviews_list = []\n",
    "\n",
    "for product in products_data['products']:\n",
    "    product_id = product['id']\n",
    "    \n",
    "    # Each product can have multiple reviews\n",
    "    for review in product.get('reviews', []):\n",
    "        reviews_list.append({\n",
    "            'product_id': product_id,  # Foreign key!\n",
    "            'rating': review['rating'],\n",
    "            'comment': review['comment'],\n",
    "            'reviewer_name': review['reviewerName'],\n",
    "            'reviewer_email': review.get('reviewerEmail', None),\n",
    "            'review_date': review.get('date', None)\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "reviews_df = pd.DataFrame(reviews_list)\n",
    "\n",
    "print(f\"✅ Created reviews table: {reviews_df.shape[0]} rows × {reviews_df.shape[1]} columns\")\n",
    "reviews_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lxfgallhpmg",
   "metadata": {},
   "source": [
    "### Validate Foreign Key Integrity\n",
    "\n",
    "> **\"In relational data, every FK must point to a valid PK. No orphans allowed!\"**\n",
    "\n",
    "**What is FK integrity?**\n",
    "- Every `reviews.product_id` must exist in `products.product_id`\n",
    "- If not, we have \"orphaned\" reviews pointing to non-existent products\n",
    "- This breaks JOINs and corrupts analysis\n",
    "\n",
    "**Business impact of orphaned FKs:**\n",
    "- ❌ Reviews can't be matched to products (data loss)\n",
    "- ❌ JOIN results are incomplete (wrong metrics)\n",
    "- ❌ Stakeholders lose trust in data quality\n",
    "\n",
    "Let's validate:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ppz2yzwtpf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.776412Z",
     "iopub.status.busy": "2025-10-12T16:28:32.776338Z",
     "iopub.status.idle": "2025-10-12T16:28:32.779143Z",
     "shell.execute_reply": "2025-10-12T16:28:32.778960Z"
    }
   },
   "outputs": [],
   "source": [
    "# Validate reviews table\n",
    "print(\"✅ Validating reviews table...\")\n",
    "\n",
    "# Check 1: Foreign key integrity\n",
    "valid_product_ids = set(products_df['product_id'])\n",
    "orphaned_reviews = ~reviews_df['product_id'].isin(valid_product_ids)\n",
    "\n",
    "assert not orphaned_reviews.any(), \\\n",
    "    f\"❌ Found {orphaned_reviews.sum()} orphaned reviews! \" \\\n",
    "    f\"These reviews have product_id values that don't exist in products table.\"\n",
    "\n",
    "print(f\"   ✓ All {len(reviews_df)} reviews have valid product_id (FK integrity passed)\")\n",
    "\n",
    "# Check 2: No NULL foreign keys\n",
    "assert reviews_df['product_id'].notna().all(), \\\n",
    "    f\"❌ Found {reviews_df['product_id'].isna().sum()} NULL product_id values in reviews!\"\n",
    "\n",
    "print(f\"   ✓ No NULL foreign keys in reviews table\")\n",
    "\n",
    "# Check 3: Rating values are in valid range\n",
    "assert reviews_df['rating'].between(1, 5).all(), \\\n",
    "    f\"❌ Found invalid ratings! Ratings must be between 1-5\"\n",
    "\n",
    "print(f\"   ✓ All ratings are in valid range (1-5)\")\n",
    "\n",
    "# Bonus: Check referential integrity statistics\n",
    "products_with_reviews = reviews_df['product_id'].nunique()\n",
    "products_without_reviews = len(products_df) - products_with_reviews\n",
    "\n",
    "print(f\"\\n📊 Referential integrity statistics:\")\n",
    "print(f\"   Products with reviews: {products_with_reviews}/{len(products_df)} ({products_with_reviews/len(products_df)*100:.1f}%)\")\n",
    "print(f\"   Products without reviews: {products_without_reviews} ({products_without_reviews/len(products_df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n✅ Reviews table validation: PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679b9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.780066Z",
     "iopub.status.busy": "2025-10-12T16:28:32.779999Z",
     "iopub.status.idle": "2025-10-12T16:28:32.782180Z",
     "shell.execute_reply": "2025-10-12T16:28:32.781996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify reviews table structure\n",
    "print(\"Reviews table info:\")\n",
    "print(f\"  Shape: {reviews_df.shape}\")\n",
    "print(f\"  Columns: {list(reviews_df.columns)}\")\n",
    "print(f\"\\n  Total reviews: {len(reviews_df)}\")\n",
    "print(f\"  Products with reviews: {reviews_df['product_id'].nunique()}\")\n",
    "print(f\"  Unique reviewers: {reviews_df['reviewer_name'].nunique()}\")\n",
    "print(f\"\\n  Reviews per product (sample):\")\n",
    "print(reviews_df.groupby('product_id').size().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5d603",
   "metadata": {},
   "source": [
    "### What We Accomplished\n",
    "\n",
    "**Before:** One nested JSON structure with products containing review arrays\n",
    "\n",
    "**After:** Two tidy tables!\n",
    "- **Products table:** 30 rows (one per product)\n",
    "- **Reviews table:** ~90 rows (one per review, multiple reviews per product)\n",
    "\n",
    "**Key insight:** We went from 30 products with nested data → ~90 separate review records.\n",
    "\n",
    "This is **normalization** - we've separated the data by observational unit (products vs. reviews).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50baf568",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Load to DuckDB (⏱️ 10-12 minutes)\n",
    "\n",
    "### Why DuckDB?\n",
    "\n",
    "**DuckDB is perfect for analytics:**\n",
    "- ✅ **Fast** - Columnar storage, optimized for analytical queries\n",
    "- ✅ **SQL interface** - Use familiar SQL syntax\n",
    "- ✅ **No server** - Embedded database (no setup, no configuration)\n",
    "- ✅ **Works with pandas** - Seamless integration\n",
    "\n",
    "**Think of it as:** \"SQLite for analytics\" or \"Postgres that runs in your Python script.\"\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4dfeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.783164Z",
     "iopub.status.busy": "2025-10-12T16:28:32.783094Z",
     "iopub.status.idle": "2025-10-12T16:28:32.788584Z",
     "shell.execute_reply": "2025-10-12T16:28:32.788366Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DuckDB connection (in-memory database)\n",
    "from IPython.display import display\n",
    "\n",
    "con = duckdb.connect(':memory:')\n",
    "\n",
    "print(\"✅ Connected to DuckDB (in-memory)\")\n",
    "print(f\"   DuckDB version: {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c597f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.789541Z",
     "iopub.status.busy": "2025-10-12T16:28:32.789484Z",
     "iopub.status.idle": "2025-10-12T16:28:32.792347Z",
     "shell.execute_reply": "2025-10-12T16:28:32.792074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write products table to DuckDB\n",
    "con.execute(\"CREATE TABLE products AS SELECT * FROM products_df\")\n",
    "\n",
    "# Verify\n",
    "row_count = con.execute(\"SELECT COUNT(*) FROM products\").fetchone()[0]\n",
    "print(f\"✅ Created 'products' table: {row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97eafb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.793422Z",
     "iopub.status.busy": "2025-10-12T16:28:32.793359Z",
     "iopub.status.idle": "2025-10-12T16:28:32.795840Z",
     "shell.execute_reply": "2025-10-12T16:28:32.795628Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write reviews table to DuckDB\n",
    "con.execute(\"CREATE TABLE reviews AS SELECT * FROM reviews_df\")\n",
    "\n",
    "# Verify\n",
    "row_count = con.execute(\"SELECT COUNT(*) FROM reviews\").fetchone()[0]\n",
    "print(f\"✅ Created 'reviews' table: {row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a2486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.796865Z",
     "iopub.status.busy": "2025-10-12T16:28:32.796798Z",
     "iopub.status.idle": "2025-10-12T16:28:32.807075Z",
     "shell.execute_reply": "2025-10-12T16:28:32.806866Z"
    }
   },
   "outputs": [],
   "source": [
    "# Verify data loaded correctly\n",
    "print(\"Tables in database:\")\n",
    "display(con.execute(\"SHOW TABLES\").df())\n",
    "\n",
    "print(\"\\nProducts preview:\")\n",
    "display(con.execute(\"SELECT * FROM products LIMIT 5\").df())\n",
    "\n",
    "print(\"\\nReviews preview:\")\n",
    "display(con.execute(\"SELECT * FROM reviews LIMIT 5\").df())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e7afe",
   "metadata": {},
   "source": [
    "### Success! JSON → DuckDB\n",
    "\n",
    "We've completed the pipeline:\n",
    "1. ✅ Fetched JSON from API\n",
    "2. ✅ Normalized nested structures to tidy tables\n",
    "3. ✅ Loaded to DuckDB for SQL analysis\n",
    "\n",
    "**Now we can use SQL to answer business questions!**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7ebe1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: SQL Analysis & Joins (⏱️ 10-12 minutes)\n",
    "\n",
    "### Business Questions We Can Now Answer\n",
    "\n",
    "With normalized tables and SQL, we can answer questions like:\n",
    "1. How many products do we have per category?\n",
    "2. What's the average review rating per product?\n",
    "3. Which products have the most reviews?\n",
    "4. Which reviewers are most active?\n",
    "\n",
    "Let's tackle each one:\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0dcd45",
   "metadata": {},
   "source": [
    "### Query 1: Products by Category\n",
    "\n",
    "**Business question:** \"How is our product catalog distributed across categories? Which categories have the most products, and what's the average price point in each category?\"\n",
    "\n",
    "**Why this matters:** Understanding category distribution helps with:\n",
    "- Inventory planning (which categories need more variety?)\n",
    "- Pricing strategy (are we positioned as premium or budget in each category?)\n",
    "- Marketing focus (which categories to promote?)\n",
    "\n",
    "Let's use GROUP BY to aggregate products by category:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8601d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.808182Z",
     "iopub.status.busy": "2025-10-12T16:28:32.808116Z",
     "iopub.status.idle": "2025-10-12T16:28:32.811270Z",
     "shell.execute_reply": "2025-10-12T16:28:32.811075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Count products by category\n",
    "print(\"Products by category:\")\n",
    "con.execute(\"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        COUNT(*) as product_count,\n",
    "        ROUND(AVG(price), 2) as avg_price\n",
    "    FROM products\n",
    "    GROUP BY category\n",
    "    ORDER BY product_count DESC\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qychunsonu",
   "metadata": {},
   "source": [
    "**What happened?**\n",
    "\n",
    "The query executed three key operations:\n",
    "1. **GROUP BY category** - Split our 30 products into groups (one per category)\n",
    "2. **COUNT(*)** - Counted how many products in each group\n",
    "3. **AVG(price)** - Calculated average price within each group\n",
    "\n",
    "**Business insights from the results:**\n",
    "- **Groceries dominates** with 15 products (50% of catalog) at low price point ($6.04 avg)\n",
    "- **Furniture** is premium category (only 5 products but $1,200 avg price)\n",
    "- **Beauty & Fragrances** are mid-tier (~5 products each, $13-$84 range)\n",
    "\n",
    "**Key SQL concept:** GROUP BY transforms row-level data into summary statistics. We went from 30 product rows → 4 category summary rows.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f59780",
   "metadata": {},
   "source": [
    "### Query 2: JOIN Products + Reviews\n",
    "\n",
    "**Business question:** \"Which products have the best customer ratings? How many reviews do they have, and are highly-rated products also highly-reviewed?\"\n",
    "\n",
    "**Why JOINs matter:** We have product data in one table and review data in another. To answer questions like \"best-reviewed products,\" we need to **combine** these tables.\n",
    "\n",
    "**This is the power of normalization:** We separated products and reviews into tidy tables. Now we can JOIN them back together to answer multi-dimensional questions.\n",
    "\n",
    "**JOIN Strategy:**\n",
    "- Use **LEFT JOIN** to keep ALL products (even those without reviews)\n",
    "- This shows us which products need more review attention\n",
    "- If we used INNER JOIN, we'd lose products with zero reviews\n",
    "\n",
    "Let's combine both tables:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a603777",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.812348Z",
     "iopub.status.busy": "2025-10-12T16:28:32.812291Z",
     "iopub.status.idle": "2025-10-12T16:28:32.818150Z",
     "shell.execute_reply": "2025-10-12T16:28:32.817956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate average review rating per product\n",
    "print(\"Top-rated products (by review ratings):\")\n",
    "con.execute(\"\"\"\n",
    "    SELECT \n",
    "        p.product_id,\n",
    "        p.title,\n",
    "        p.category,\n",
    "        p.price,\n",
    "        COUNT(r.rating) as review_count,\n",
    "        ROUND(AVG(r.rating), 2) as avg_review_rating\n",
    "    FROM products p\n",
    "    LEFT JOIN reviews r ON p.product_id = r.product_id\n",
    "    GROUP BY p.product_id, p.title, p.category, p.price\n",
    "    ORDER BY avg_review_rating DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i74hnh3ttaa",
   "metadata": {},
   "source": [
    "**What happened?**\n",
    "\n",
    "This query demonstrates the complete **normalization → JOIN → aggregation** pipeline:\n",
    "\n",
    "1. **LEFT JOIN** - Connected products table with reviews table using `product_id` as the foreign key\n",
    "2. **GROUP BY** - Aggregated reviews per product (collapsed multiple reviews → one row per product)\n",
    "3. **COUNT(r.rating)** - Counted how many reviews each product has\n",
    "4. **AVG(r.rating)** - Calculated average rating from all reviews\n",
    "\n",
    "**Business insights from the results:**\n",
    "- All top-rated products have **exactly 3 reviews** - This is consistent (our dataset has 3 reviews per product)\n",
    "- Multiple products tied at **4.67 stars** - These are our best-reviewed items\n",
    "- The query shows **product_id, title, category, price** alongside review metrics\n",
    "\n",
    "**Key SQL concept - LEFT JOIN preserves all products:**\n",
    "- If a product had 0 reviews, it would still appear in results with `review_count = 0` and `avg_review_rating = NULL`\n",
    "- This is different from INNER JOIN, which would exclude products without reviews entirely\n",
    "\n",
    "**Why this matters for business:** You can now identify:\n",
    "- Products with high ratings AND high review counts (social proof!)\n",
    "- Products with few reviews (opportunity to gather more feedback)\n",
    "- Category patterns in ratings (are beauty products rated higher than groceries?)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rgh09a06dm",
   "metadata": {},
   "source": [
    "### Common Mistakes with JOINs & Aggregations\n",
    "\n",
    "> **🚨 These mistakes will cost you hours of debugging. Learn them now!**\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ Mistake 1: Forgetting the JOIN Condition (Accidental CROSS JOIN)\n",
    "\n",
    "**Wrong:**\n",
    "```sql\n",
    "SELECT p.title, r.rating\n",
    "FROM products p, reviews r  -- Missing ON condition!\n",
    "```\n",
    "\n",
    "**What happens:** Every product × every review = 30 × 90 = **2,700 rows** instead of 90!\n",
    "\n",
    "**✅ Correct:**\n",
    "```sql\n",
    "SELECT p.title, r.rating\n",
    "FROM products p\n",
    "LEFT JOIN reviews r ON p.product_id = r.product_id  -- Explicit JOIN condition\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ Mistake 2: Using INNER JOIN When You Need LEFT JOIN\n",
    "\n",
    "**Business question:** \"Show me ALL products and their review counts (including products with zero reviews)\"\n",
    "\n",
    "**Wrong:**\n",
    "```sql\n",
    "SELECT p.title, COUNT(r.rating) as review_count\n",
    "FROM products p\n",
    "INNER JOIN reviews r ON p.product_id = r.product_id  -- ❌ Loses products without reviews!\n",
    "GROUP BY p.title\n",
    "```\n",
    "\n",
    "**What happens:** Products with 0 reviews don't appear in results at all.\n",
    "\n",
    "**✅ Correct:**\n",
    "```sql\n",
    "SELECT p.title, COUNT(r.rating) as review_count\n",
    "FROM products p\n",
    "LEFT JOIN reviews r ON p.product_id = r.product_id  -- ✅ Keeps all products\n",
    "GROUP BY p.title\n",
    "```\n",
    "\n",
    "**Remember:** LEFT JOIN preserves all rows from the LEFT table (products), even if no match in RIGHT table (reviews).\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ Mistake 3: Forgetting GROUP BY Columns\n",
    "\n",
    "**Wrong:**\n",
    "```sql\n",
    "SELECT p.title, p.category, COUNT(r.rating)\n",
    "FROM products p\n",
    "LEFT JOIN reviews r ON p.product_id = r.product_id\n",
    "GROUP BY p.title  -- ❌ Missing p.category in GROUP BY!\n",
    "```\n",
    "\n",
    "**SQL Rule:** Every non-aggregated column in SELECT must be in GROUP BY.\n",
    "\n",
    "**✅ Correct:**\n",
    "```sql\n",
    "SELECT p.title, p.category, COUNT(r.rating)\n",
    "FROM products p\n",
    "LEFT JOIN reviews r ON p.product_id = r.product_id\n",
    "GROUP BY p.title, p.category  -- ✅ All non-aggregated columns included\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ❌ Mistake 4: Using COUNT(*) vs COUNT(column) with LEFT JOIN\n",
    "\n",
    "**Scenario:** Product has 0 reviews (no matching rows in reviews table).\n",
    "\n",
    "**Query:**\n",
    "```sql\n",
    "SELECT p.title, COUNT(*), COUNT(r.rating)\n",
    "FROM products p\n",
    "LEFT JOIN reviews r ON p.product_id = r.product_id\n",
    "GROUP BY p.title\n",
    "```\n",
    "\n",
    "**For a product with 0 reviews:**\n",
    "- `COUNT(*)` = **1** (counts the product row, even though review columns are NULL)\n",
    "- `COUNT(r.rating)` = **0** (counts only non-NULL values)\n",
    "\n",
    "**✅ With LEFT JOIN, use `COUNT(column)` not `COUNT(*)`** to count actual matches!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vl51y05egk",
   "metadata": {},
   "source": [
    "### Decision Guide: Which JOIN Type to Use?\n",
    "\n",
    "> **Ask yourself: \"Do I need ALL rows from the left table, or only matches?\"**\n",
    "\n",
    "---\n",
    "\n",
    "| Business Scenario | Use This JOIN | Why |\n",
    "|-------------------|---------------|-----|\n",
    "| \"Show ALL products and their review counts\" | **LEFT JOIN** | Preserves products without reviews |\n",
    "| \"Show ALL customers and their order totals\" | **LEFT JOIN** | Preserves customers who haven't ordered |\n",
    "| \"Show ONLY products that have been reviewed\" | **INNER JOIN** | Excludes products without reviews |\n",
    "| \"Show ONLY customers who have placed orders\" | **INNER JOIN** | Excludes customers without orders |\n",
    "| \"Show ALL products AND all reviews (even orphaned reviews)\" | **FULL OUTER JOIN** | Rare in practice |\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Decision Tree\n",
    "\n",
    "```\n",
    "Do you need rows from the left table even if there's no match?\n",
    "│\n",
    "├─ YES → Use LEFT JOIN\n",
    "│   Examples:\n",
    "│   - \"All products\" (some might not have reviews)\n",
    "│   - \"All customers\" (some might not have orders)\n",
    "│\n",
    "└─ NO → Use INNER JOIN\n",
    "    Examples:\n",
    "    - \"Only reviewed products\"\n",
    "    - \"Only customers with orders\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### In Our E-Commerce Example\n",
    "\n",
    "**LEFT JOIN (what we used):**\n",
    "```sql\n",
    "-- Show ALL products and their review metrics\n",
    "SELECT p.title, COUNT(r.rating) as review_count\n",
    "FROM products p\n",
    "LEFT JOIN reviews r ON p.product_id = r.product_id\n",
    "GROUP BY p.title\n",
    "```\n",
    "**Result:** All 30 products appear. Products without reviews show `review_count = 0`.\n",
    "\n",
    "**INNER JOIN (alternative):**\n",
    "```sql\n",
    "-- Show ONLY products that have been reviewed\n",
    "SELECT p.title, COUNT(r.rating) as review_count\n",
    "FROM products p\n",
    "INNER JOIN reviews r ON p.product_id = r.product_id\n",
    "GROUP BY p.title\n",
    "```\n",
    "**Result:** Only products with ≥1 review appear. (In our dataset, that's all 30, but in real data it might be fewer.)\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use RIGHT JOIN\n",
    "\n",
    "**Almost never!** RIGHT JOIN is the same as LEFT JOIN with tables swapped. Just swap the table order and use LEFT JOIN for clarity:\n",
    "\n",
    "❌ **Confusing:**\n",
    "```sql\n",
    "FROM products p\n",
    "RIGHT JOIN reviews r ON p.product_id = r.product_id\n",
    "```\n",
    "\n",
    "✅ **Clear:**\n",
    "```sql\n",
    "FROM reviews r\n",
    "LEFT JOIN products p ON r.product_id = p.product_id\n",
    "```\n",
    "\n",
    "**Convention:** Always put the \"main\" table (the one you want to preserve) on the LEFT and use LEFT JOIN.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1604hsyfeco",
   "metadata": {},
   "source": [
    "### ⏸️ Pause and Try!\n",
    "\n",
    "**Your task:** Write a query to analyze reviewers and their rating patterns.\n",
    "\n",
    "**Business question:** \"Which reviewers have left the most reviews, and what's their average rating? Are frequent reviewers more generous or more critical?\"\n",
    "\n",
    "**Requirements:**\n",
    "1. JOIN the `products` and `reviews` tables\n",
    "2. GROUP BY reviewer name\n",
    "3. Calculate:\n",
    "   - Count of reviews per reviewer (`COUNT(r.rating)`)\n",
    "   - Average rating given by each reviewer (`AVG(r.rating)`)\n",
    "4. Filter to show ONLY reviewers with **2 or more reviews** (use `HAVING`)\n",
    "5. Order results by review count descending\n",
    "6. Limit to top 15 reviewers\n",
    "\n",
    "**Hint structure:**\n",
    "```sql\n",
    "SELECT \n",
    "    r.reviewer_name,\n",
    "    ??? as review_count,\n",
    "    ??? as avg_rating_given\n",
    "FROM ??? p\n",
    "LEFT JOIN ??? r ON ???\n",
    "GROUP BY ???\n",
    "HAVING ??? >= 2\n",
    "ORDER BY ??? DESC\n",
    "LIMIT 15\n",
    "```\n",
    "\n",
    "**Replace the `???` placeholders and complete the query below:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20utdkj6kc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:28:32.819214Z",
     "iopub.status.busy": "2025-10-12T16:28:32.819147Z",
     "iopub.status.idle": "2025-10-12T16:28:32.821433Z",
     "shell.execute_reply": "2025-10-12T16:28:32.821238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your turn! Write your query here:\n",
    "#\n",
    "# TODO: Replace this placeholder with your complete query\n",
    "\n",
    "con.execute(\"SELECT 1 AS todo\").df()  # Replace this entire query with your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec47bd5c",
   "metadata": {},
   "source": [
    "### Key SQL Concepts Used\n",
    "\n",
    "**LEFT JOIN:**\n",
    "- Keeps ALL products (even those without reviews)\n",
    "- Matches reviews where `product_id` matches\n",
    "- If no reviews exist, review columns are NULL\n",
    "\n",
    "**GROUP BY:**\n",
    "- Aggregates reviews per product\n",
    "- `COUNT(r.rating)` counts how many reviews each product has\n",
    "- `AVG(r.rating)` calculates average rating\n",
    "\n",
    "**Business insight:** We can now see which products have the best reviews and how many reviews they received.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary & What We Accomplished\n",
    "\n",
    "### The Complete Pipeline: API → DuckDB → Insights\n",
    "\n",
    "**We demonstrated the end-to-end modern data pipeline:**\n",
    "\n",
    "1. **Fetch** - Retrieved JSON from DummyJSON API\n",
    "2. **Normalize** - Flattened nested structures (products + reviews)\n",
    "3. **Persist** - Loaded tidy tables into DuckDB\n",
    "4. **Analyze** - Used SQL to answer business questions\n",
    "5. **Validate** - Checked data quality at each step\n",
    "\n",
    "### Key Patterns You Learned\n",
    "\n",
    "✅ **Normalization** - Separate observational units into different tables  \n",
    "✅ **Foreign keys** - Connect related tables (`product_id` links reviews to products)  \n",
    "✅ **Pandas transformation** - Use Python for complex data manipulation  \n",
    "✅ **DuckDB integration** - SQL analysis on pandas DataFrames  \n",
    "✅ **JOINs** - Combine tables to answer multi-dimensional questions  \n",
    "\n",
    "### This is Homework 2!\n",
    "\n",
    "**HW2 will ask you to:**\n",
    "1. Fetch data from a different API (or JSON file)\n",
    "2. Normalize nested structures into tidy tables\n",
    "3. Load to DuckDB\n",
    "4. Write 3-5 SQL queries to calculate business KPIs\n",
    "5. Add validation assertions\n",
    "6. Document your pipeline with a data dictionary\n",
    "\n",
    "**You now have the pattern!** This notebook is your template.\n",
    "\n",
    "---\n",
    "\n",
    "## Where to Go Next\n",
    "\n",
    "### Production Enhancements (Reference)\n",
    "\n",
    "For production systems, you'd add:\n",
    "- **`requests.Session()`** - Connection pooling for better performance\n",
    "- **`tenacity`** - Automatic retry logic for API failures\n",
    "- **Error handling** - Try/except blocks around API calls\n",
    "- **Logging** - Track what happened, when, and why\n",
    "- **Data validation** - More assertions (PK uniqueness, FK integrity, type checks)\n",
    "- **Incremental loads** - Only fetch new data (not full refresh)\n",
    "\n",
    "**See:** `references/api_pipeline_quick_reference.md` for production patterns.\n",
    "\n",
    "### HW2: Due Wednesday, Oct 22 (start of class)\n",
    "\n",
    "**Assignment:** Build a mini-pipeline similar to this notebook\n",
    "- Different API/JSON source\n",
    "- Normalize to 2-3 tables\n",
    "- 3-5 SQL KPIs\n",
    "- Validation assertions\n",
    "- Data dictionary\n",
    "\n",
    "**Instructor will present HW2 details next!**\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
