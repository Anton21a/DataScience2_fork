{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b73a1e",
   "metadata": {},
   "source": [
    "# Day 2, Block B: JSON → DuckDB Pipeline\n",
    "\n",
    "**Duration:** 40-45 minutes  \n",
    "**Course:** ECBS5294 - Introduction to Data Science: Working with Data  \n",
    "**Instructor:** Eduardo Ariño de la Rubia\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "\n",
    "1. **Explain** why nested JSON needs normalization (tidy data principles)\n",
    "2. **Normalize** nested JSON structures into multiple related tables\n",
    "3. **Use pandas** to flatten one-to-many relationships\n",
    "4. **Persist** normalized data to DuckDB for SQL analysis\n",
    "5. **Join** normalized tables to answer business questions\n",
    "6. **Validate** data quality with assertions\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b26d64",
   "metadata": {},
   "source": [
    "## Part 1: The Normalization Problem (⏱️ 8-10 minutes)\n",
    "\n",
    "### Recall: Tidy Data Principles (Day 1)\n",
    "\n",
    "On Day 1, we learned **tidy data principles:**\n",
    "\n",
    "1. Each **variable** is a column\n",
    "2. Each **observation** is a row\n",
    "3. Each **type of observational unit** forms a table\n",
    "\n",
    "**The problem:** Nested JSON violates these principles!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f516621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d05a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1: Use live API (DEFAULT)\n",
    "DUMMYJSON_URL = \"https://dummyjson.com/products\"\n",
    "\n",
    "response = requests.get(DUMMYJSON_URL, params={'limit': 30}, timeout=10)\n",
    "response.raise_for_status()\n",
    "products_data = response.json()\n",
    "\n",
    "print(f\"✅ Fetched {len(products_data['products'])} products from API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35993db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: Use backup file (if API is down)\n",
    "# Uncomment these lines and skip the cell above if DummyJSON is unavailable\n",
    "\n",
    "# import json\n",
    "# with open('../../data/day2/block_b/products_backup.json') as f:\n",
    "#     products_data = json.load(f)\n",
    "# \n",
    "# print(f\"✅ Loaded {len(products_data['products'])} products from backup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd28a187",
   "metadata": {},
   "source": [
    "### The Problem: One-to-Many Relationships\n",
    "\n",
    "Look at a single product with its nested reviews:\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9cafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine one product with nested reviews\n",
    "sample_product = products_data['products'][0]\n",
    "\n",
    "print(\"Product structure:\")\n",
    "print(f\"  ID: {sample_product['id']}\")\n",
    "print(f\"  Title: {sample_product['title']}\")\n",
    "print(f\"  Price: ${sample_product['price']}\")\n",
    "print(f\"\\n  Reviews ({len(sample_product['reviews'])} reviews):\")\n",
    "\n",
    "for i, review in enumerate(sample_product['reviews'], 1):\n",
    "    print(f\"    Review {i}: {review['rating']}⭐ - {review['reviewerName']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Problem: One product has MANY reviews.\")\n",
    "print(\"This is a ONE-TO-MANY relationship - not tidy!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea50af7",
   "metadata": {},
   "source": [
    "### Why This Matters for Business\n",
    "\n",
    "**Questions we want to answer:**\n",
    "- What's the average rating across all reviews? (need to count reviews, not products!)\n",
    "- Which reviewers are most active? (need to count by reviewer)\n",
    "- How many reviews per product? (need to aggregate reviews by product)\n",
    "\n",
    "**We can't answer these questions cleanly with nested JSON.**\n",
    "\n",
    "**Solution:** Create two separate tables:\n",
    "1. **Products table** - One row per product (product-level attributes only)\n",
    "2. **Reviews table** - One row per review (with `product_id` foreign key)\n",
    "\n",
    "This is called **normalization** - the process of organizing data to reduce redundancy and improve integrity.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334784ab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Normalize with Pandas (⏱️ 12-15 minutes)\n",
    "\n",
    "### Strategy: Create Multiple Tidy Tables\n",
    "\n",
    "We'll create two tables:\n",
    "1. **`products`** - Product-level attributes (id, title, price, category, brand, stock)\n",
    "2. **`reviews`** - Review-level attributes (product_id, rating, comment, reviewer)\n",
    "\n",
    "The `product_id` in the reviews table is a **foreign key** that links back to the products table.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a789bc1",
   "metadata": {},
   "source": [
    "### Step 1: Extract Products Table\n",
    "\n",
    "First, let's create a DataFrame with only product-level attributes:\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract products (top-level attributes only)\n",
    "products_list = []\n",
    "\n",
    "for product in products_data['products']:\n",
    "    products_list.append({\n",
    "        'product_id': product['id'],\n",
    "        'title': product['title'],\n",
    "        'price': product['price'],\n",
    "        'category': product['category'],\n",
    "        'brand': product.get('brand', 'Unknown'),  # Safe access\n",
    "        'stock': product.get('stock', 0),\n",
    "        'rating': product.get('rating', None)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "products_df = pd.DataFrame(products_list)\n",
    "\n",
    "print(f\"✅ Created products table: {products_df.shape[0]} rows × {products_df.shape[1]} columns\")\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify products table structure\n",
    "print(\"Products table info:\")\n",
    "print(f\"  Shape: {products_df.shape}\")\n",
    "print(f\"  Columns: {list(products_df.columns)}\")\n",
    "print(f\"  Data types:\\n{products_df.dtypes}\")\n",
    "print(f\"\\n  Unique products: {products_df['product_id'].nunique()}\")\n",
    "print(f\"  Categories: {products_df['category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317b811",
   "metadata": {},
   "source": [
    "### Step 2: Extract Reviews Table (Explode One-to-Many)\n",
    "\n",
    "Now for the tricky part: **exploding the reviews array** into separate rows.\n",
    "\n",
    "Each review becomes its own row, with a `product_id` foreign key linking back to the product.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51cb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reviews (explode one-to-many)\n",
    "reviews_list = []\n",
    "\n",
    "for product in products_data['products']:\n",
    "    product_id = product['id']\n",
    "    \n",
    "    # Each product can have multiple reviews\n",
    "    for review in product.get('reviews', []):\n",
    "        reviews_list.append({\n",
    "            'product_id': product_id,  # Foreign key!\n",
    "            'rating': review['rating'],\n",
    "            'comment': review['comment'],\n",
    "            'reviewer_name': review['reviewerName'],\n",
    "            'reviewer_email': review.get('reviewerEmail', None),\n",
    "            'review_date': review.get('date', None)\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "reviews_df = pd.DataFrame(reviews_list)\n",
    "\n",
    "print(f\"✅ Created reviews table: {reviews_df.shape[0]} rows × {reviews_df.shape[1]} columns\")\n",
    "reviews_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7679b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify reviews table structure\n",
    "print(\"Reviews table info:\")\n",
    "print(f\"  Shape: {reviews_df.shape}\")\n",
    "print(f\"  Columns: {list(reviews_df.columns)}\")\n",
    "print(f\"\\n  Total reviews: {len(reviews_df)}\")\n",
    "print(f\"  Products with reviews: {reviews_df['product_id'].nunique()}\")\n",
    "print(f\"  Unique reviewers: {reviews_df['reviewer_name'].nunique()}\")\n",
    "print(f\"\\n  Reviews per product (sample):\")\n",
    "print(reviews_df.groupby('product_id').size().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5d603",
   "metadata": {},
   "source": [
    "### What We Accomplished\n",
    "\n",
    "**Before:** One nested JSON structure with products containing review arrays\n",
    "\n",
    "**After:** Two tidy tables!\n",
    "- **Products table:** 30 rows (one per product)\n",
    "- **Reviews table:** ~90 rows (one per review, multiple reviews per product)\n",
    "\n",
    "**Key insight:** We went from 30 products with nested data → ~90 separate review records.\n",
    "\n",
    "This is **normalization** - we've separated the data by observational unit (products vs. reviews).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50baf568",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Load to DuckDB (⏱️ 10-12 minutes)\n",
    "\n",
    "### Why DuckDB?\n",
    "\n",
    "**DuckDB is perfect for analytics:**\n",
    "- ✅ **Fast** - Columnar storage, optimized for analytical queries\n",
    "- ✅ **SQL interface** - Use familiar SQL syntax\n",
    "- ✅ **No server** - Embedded database (no setup, no configuration)\n",
    "- ✅ **Works with pandas** - Seamless integration\n",
    "\n",
    "**Think of it as:** \"SQLite for analytics\" or \"Postgres that runs in your Python script.\"\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DuckDB connection (in-memory database)\n",
    "con = duckdb.connect(':memory:')\n",
    "\n",
    "print(\"✅ Connected to DuckDB (in-memory)\")\n",
    "print(f\"   DuckDB version: {duckdb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write products table to DuckDB\n",
    "con.execute(\"CREATE TABLE products AS SELECT * FROM products_df\")\n",
    "\n",
    "# Verify\n",
    "row_count = con.execute(\"SELECT COUNT(*) FROM products\").fetchone()[0]\n",
    "print(f\"✅ Created 'products' table: {row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write reviews table to DuckDB\n",
    "con.execute(\"CREATE TABLE reviews AS SELECT * FROM reviews_df\")\n",
    "\n",
    "# Verify\n",
    "row_count = con.execute(\"SELECT COUNT(*) FROM reviews\").fetchone()[0]\n",
    "print(f\"✅ Created 'reviews' table: {row_count} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data loaded correctly\n",
    "print(\"Tables in database:\")\n",
    "tables = con.execute(\"SHOW TABLES\").df()\n",
    "print(tables)\n",
    "\n",
    "print(\"\\nProducts preview:\")\n",
    "print(con.execute(\"SELECT * FROM products LIMIT 5\").df())\n",
    "\n",
    "print(\"\\nReviews preview:\")\n",
    "print(con.execute(\"SELECT * FROM reviews LIMIT 5\").df())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518e7afe",
   "metadata": {},
   "source": [
    "### Success! JSON → DuckDB\n",
    "\n",
    "We've completed the pipeline:\n",
    "1. ✅ Fetched JSON from API\n",
    "2. ✅ Normalized nested structures to tidy tables\n",
    "3. ✅ Loaded to DuckDB for SQL analysis\n",
    "\n",
    "**Now we can use SQL to answer business questions!**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7ebe1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: SQL Analysis & Joins (⏱️ 10-12 minutes)\n",
    "\n",
    "### Business Questions We Can Now Answer\n",
    "\n",
    "With normalized tables and SQL, we can answer questions like:\n",
    "1. How many products do we have per category?\n",
    "2. What's the average review rating per product?\n",
    "3. Which products have the most reviews?\n",
    "4. Which reviewers are most active?\n",
    "\n",
    "Let's tackle each one:\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0dcd45",
   "metadata": {},
   "source": [
    "### Query 1: Products by Category\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8601d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count products by category\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        category,\n",
    "        COUNT(*) as product_count,\n",
    "        ROUND(AVG(price), 2) as avg_price\n",
    "    FROM products\n",
    "    GROUP BY category\n",
    "    ORDER BY product_count DESC\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Products by category:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f59780",
   "metadata": {},
   "source": [
    "### Query 2: JOIN Products + Reviews\n",
    "\n",
    "Now let's combine both tables to calculate average rating per product:\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a603777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average review rating per product\n",
    "result = con.execute(\"\"\"\n",
    "    SELECT \n",
    "        p.product_id,\n",
    "        p.title,\n",
    "        p.category,\n",
    "        p.price,\n",
    "        COUNT(r.rating) as review_count,\n",
    "        ROUND(AVG(r.rating), 2) as avg_review_rating\n",
    "    FROM products p\n",
    "    LEFT JOIN reviews r ON p.product_id = r.product_id\n",
    "    GROUP BY p.product_id, p.title, p.category, p.price\n",
    "    ORDER BY avg_review_rating DESC\n",
    "    LIMIT 10\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Top-rated products (by review ratings):\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec47bd5c",
   "metadata": {},
   "source": [
    "### Key SQL Concepts Used\n",
    "\n",
    "**LEFT JOIN:**\n",
    "- Keeps ALL products (even those without reviews)\n",
    "- Matches reviews where `product_id` matches\n",
    "- If no reviews exist, review columns are NULL\n",
    "\n",
    "**GROUP BY:**\n",
    "- Aggregates reviews per product\n",
    "- `COUNT(r.rating)` counts how many reviews each product has\n",
    "- `AVG(r.rating)` calculates average rating\n",
    "\n",
    "**Business insight:** We can now see which products have the best reviews and how many reviews they received.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary & What We Accomplished\n",
    "\n",
    "### The Complete Pipeline: API → DuckDB → Insights\n",
    "\n",
    "**We demonstrated the end-to-end modern data pipeline:**\n",
    "\n",
    "1. **Fetch** - Retrieved JSON from DummyJSON API\n",
    "2. **Normalize** - Flattened nested structures (products + reviews)\n",
    "3. **Persist** - Loaded tidy tables into DuckDB\n",
    "4. **Analyze** - Used SQL to answer business questions\n",
    "5. **Validate** - Checked data quality at each step\n",
    "\n",
    "### Key Patterns You Learned\n",
    "\n",
    "✅ **Normalization** - Separate observational units into different tables  \n",
    "✅ **Foreign keys** - Connect related tables (`product_id` links reviews to products)  \n",
    "✅ **Pandas transformation** - Use Python for complex data manipulation  \n",
    "✅ **DuckDB integration** - SQL analysis on pandas DataFrames  \n",
    "✅ **JOINs** - Combine tables to answer multi-dimensional questions  \n",
    "\n",
    "### This is Homework 2!\n",
    "\n",
    "**HW2 will ask you to:**\n",
    "1. Fetch data from a different API (or JSON file)\n",
    "2. Normalize nested structures into tidy tables\n",
    "3. Load to DuckDB\n",
    "4. Write 3-5 SQL queries to calculate business KPIs\n",
    "5. Add validation assertions\n",
    "6. Document your pipeline with a data dictionary\n",
    "\n",
    "**You now have the pattern!** This notebook is your template.\n",
    "\n",
    "---\n",
    "\n",
    "## Where to Go Next\n",
    "\n",
    "### Production Enhancements (Reference)\n",
    "\n",
    "For production systems, you'd add:\n",
    "- **`requests.Session()`** - Connection pooling for better performance\n",
    "- **`tenacity`** - Automatic retry logic for API failures\n",
    "- **Error handling** - Try/except blocks around API calls\n",
    "- **Logging** - Track what happened, when, and why\n",
    "- **Data validation** - More assertions (PK uniqueness, FK integrity, type checks)\n",
    "- **Incremental loads** - Only fetch new data (not full refresh)\n",
    "\n",
    "**See:** `references/api_pipeline_quick_reference.md` for production patterns.\n",
    "\n",
    "### HW2: Due Wednesday, Oct 22 (start of class)\n",
    "\n",
    "**Assignment:** Build a mini-pipeline similar to this notebook\n",
    "- Different API/JSON source\n",
    "- Normalize to 2-3 tables\n",
    "- 3-5 SQL KPIs\n",
    "- Validation assertions\n",
    "- Data dictionary\n",
    "\n",
    "**Instructor will present HW2 details next!**\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
